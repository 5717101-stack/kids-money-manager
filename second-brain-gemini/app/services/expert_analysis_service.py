"""
Expert Analysis Service - Council of Experts for Meeting Analysis

This service applies expert personas to analyze transcribed conversations:
- Michal Dalyot / Adler Institute (Parenting/Boundaries)
- Esther Perel (Relationships/Communication)
- McKinsey & Co. / Israeli Tech (Business/Strategy)
- Simon Sinek (Leadership/The Why)

Each persona provides:
- Sentiment analysis
- Executive summary
- Expert insights
- Action items (assigned to specific speakers)
- Mandatory Kaizen Feedback (×œ×©×™××•×¨ / ×œ×©×™×¤×•×¨)
"""

import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone, timedelta

import google.generativeai as genai

from app.core.config import settings

logger = logging.getLogger(__name__)

# Israel timezone offset (UTC+2 winter, UTC+3 summer)
ISRAEL_TZ_OFFSET = timedelta(hours=2)


def get_israel_time() -> datetime:
    """Get current time in Israel timezone."""
    utc_now = datetime.now(timezone.utc)
    return utc_now + ISRAEL_TZ_OFFSET


# Council of Experts - Persona Definitions
EXPERT_PERSONAS = {
    "parenting": {
        "name": "××™×›×œ ×“×œ×™×•×ª / ××›×•×Ÿ ××“×œ×¨ (×”×•×¨×•×ª ×•×’×‘×•×œ×•×ª)",
        "short_name": "××›×•×Ÿ ××“×œ×¨",
        "trigger_keywords": [
            "×™×œ×“×™×", "×‘× ×™×", "×‘× ×•×ª", "×‘×™×ª", "×—×™× ×•×š", "××˜×œ×•×ª", "×©×™×¢×•×¨×™ ×‘×™×ª",
            "kids", "children", "×”×•×¨×™×", "××©×¤×—×”", "×’×‘×•×œ×•×ª", "×›×œ×œ×™×",
            "×™×œ×“", "×™×œ×“×”", "×‘×Ÿ", "×‘×ª", "×”×ª× ×”×’×•×ª", "××©××¢×ª"
        ],
        "focus": """
×’×™×©×ª ××“×œ×¨ ×œ×”×•×¨×•×ª ×“××•×§×¨×˜×™×ª:
- ×¢×™×“×•×“ ×‘××§×•× ×©×‘×— (Encouragement vs Praise)
- ×ª×•×¦××•×ª ×˜×‘×¢×™×•×ª ×•×”×’×™×•× ×™×•×ª (Natural & Logical Consequences)
- ×©×™×ª×•×£ ×¤×¢×•×œ×” ×•××—×¨×™×•×ª ××©×•×ª×¤×ª
- ×”×™×× ×¢×•×ª ××××‘×§×™ ×›×•×—
- ×›×‘×•×“ ×”×“×“×™ ×•×’×‘×•×œ×•×ª ×‘×¨×•×¨×™×
- ××ª×Ÿ ×‘×—×™×¨×•×ª ×‘××¡×’×¨×ª ×’×‘×•×œ×•×ª
""",
        "tone": "×ª×•××š, ×¤×¨×§×˜×™, ×—×™× ×•×›×™, ×œ×œ× ×©×™×¤×•×˜×™×•×ª"
    },
    "relationship": {
        "name": "××¡×ª×¨ ×¤×¨×œ (×™×—×¡×™× ×•×ª×§×©×•×¨×ª)",
        "short_name": "××¡×ª×¨ ×¤×¨×œ",
        "trigger_keywords": [
            "×‘×¢×œ", "××™×©×”", "×–×•×’×™×•×ª", "×¨×’×©×•×ª", "××”×‘×”", "relationship", "partner",
            "×¢×¨×Ÿ", "×–×•×’", "×›×¢×¡", "×ª×¡×›×•×œ", "××™× ×˜×™××™×•×ª", "×§×©×¨", "×—×™×‘×•×¨",
            "×¨×™×‘", "×•×™×›×•×—", "×œ× ××‘×™×Ÿ", "×œ× ××‘×™× ×”"
        ],
        "focus": """
×’×™×©×ª ××¡×ª×¨ ×¤×¨×œ ×œ×–×•×’×™×•×ª:
- ××™× ×˜×œ×™×’× ×¦×™×” ×¨×’×©×™×ª ×¢××•×§×”
- ××™×–×•×Ÿ ×‘×™×Ÿ ×‘×™×˜×—×•×Ÿ (Security) ×œ×—×•×¤×© (Freedom)
- ×”×§×©×‘×” ×œ"×œ× × ×××¨" - ××” ×‘×™×Ÿ ×”×©×•×¨×•×ª
- ×”×‘× ×ª ×“×™× ××™×§×•×ª ×›×•×— × ×¡×ª×¨×•×ª
- ×¤×™×©×•×¨ ×‘×™×Ÿ ×ª×©×•×§×” ×œ×—×™×™ ×™×•×-×™×•×
- ×–×™×”×•×™ ×“×¤×•×¡×™× ×—×•×–×¨×™× ×‘×ª×§×©×•×¨×ª
""",
        "tone": "×××¤×ª×™, ×¢××•×§, ×ª×•×‘× ×ª×™, ×œ×œ× ×©×™×¤×•×˜"
    },
    "strategy": {
        "name": "××§×™× ×–×™ ×•×˜×§ ×™×©×¨××œ×™ (××¡×˜×¨×˜×’×™×” ×•×¢×¡×§×™×)",
        "short_name": "××§×™× ×–×™ + Tech",
        "trigger_keywords": [
            "×¢×¡×§", "××•×¦×¨", "×œ×§×•×—×•×ª", "××¡×˜×¨×˜×’×™×”", "roadmap", "MVP", "startup",
            "product", "×›×¡×£", "×ª×§×¦×™×‘", "×”×›× ×¡×•×ª", "××›×™×¨×•×ª", "×©×•×§", "××ª×—×¨×™×",
            "×¤×™×¦'×¨", "×¤×™×ª×•×—", "tech", "×§×•×“", "××©×§×™×¢×™×", "×’×™×•×¡", "×—×‘×¨×”"
        ],
        "focus": """
×’×™×©×ª ××§×™× ×–×™ + High-Tech ×™×©×¨××œ×™:
- ××‘× ×” MECE (Mutually Exclusive, Collectively Exhaustive)
- × ×™×ª×•×— ××‘×•×¡×¡ × ×ª×•× ×™× (Data-Driven)
- ×¡×§×™×™×œ×‘×™×œ×™×•×ª ×•×™×¢×™×œ×•×ª
- ×—×©×™×‘×ª Agile/Lean Startup
- MVP ×•××™×˜×¨×¦×™×•×ª ××”×™×¨×•×ª
- ×”×’×“×¨×ª KPIs ×‘×¨×•×¨×™×
- ×ª×¢×“×•×£ ××›×–×¨×™ (Ruthless Prioritization)
""",
        "tone": "×—×“, ××§×¦×•×¢×™, ×××•×§×“ ×¤×¢×•×œ×”, ×—×•×ª×š ×œ×¢× ×™×™×Ÿ"
    },
    "leadership": {
        "name": "×¡×™×™××•×Ÿ ×¡×™× ×§ (×× ×”×™×’×•×ª ×•×”×©×¨××”)",
        "short_name": "×¡×™×™××•×Ÿ ×¡×™× ×§",
        "trigger_keywords": [
            "×¦×•×•×ª", "×¢×•×‘×“×™×", "×× ×”×œ", "×—×‘×¨×”", "×ª×¨×‘×•×ª", "hiring", "mentoring",
            "culture", "×× ×”×™×’×•×ª", "×”×©×¨××”", "×¢×¨×›×™×", "×—×–×•×Ÿ", "××©××¢×•×ª",
            "××•×˜×™×‘×¦×™×”", "×’×™×•×¡", "×¤×™×˜×•×¨×™×", "×‘×™×¦×•×¢×™×", "××©×•×‘"
        ],
        "focus": """
×’×™×©×ª ×¡×™×™××•×Ÿ ×¡×™× ×§ ×œ×× ×”×™×’×•×ª:
- Start with Why - ×ª×ª×—×™×œ ××”"×œ××”"
- The Infinite Game - ××©×—×§ ××™× ×¡×•×¤×™, ×œ× × ×™×¦×—×•×Ÿ ×—×“ ×¤×¢××™
- Circle of Safety - ×™×¦×™×¨×ª ××¢×’×œ ×‘×™×˜×—×•×Ÿ ×œ×¦×•×•×ª
- Leaders Eat Last - ×× ×”×™×’ ×“×•××’ ×§×•×“× ×œ××—×¨×™×
- ×× ×”×™×’×•×ª ××©×¨×ª×ª (Servant Leadership)
- ×‘× ×™×™×ª ×××•×Ÿ ×œ×˜×•×•×— ××¨×•×š
""",
        "tone": "××¢×•×¨×¨ ×”×©×¨××”, ×××•×§×“ ×‘×× ×©×™×, ×—×–×•× ×™, ×× ×•×©×™"
    },
    "general": {
        "name": "×¢×•×–×¨ ××™×©×™ ×—×›×",
        "short_name": "×¢×•×–×¨ ××™×©×™",
        "trigger_keywords": [],
        "focus": "×¡×™×›×•× ×‘×¨×•×¨ ×•×ª××¦×™×ª×™ ×¢× ×ª×•×‘× ×•×ª ×¤×¨×§×˜×™×•×ª ×•××§×©×Ÿ ××™×™×˜××¡",
        "tone": "×™×©×™×¨, ×©×™××•×©×™, ×¤×¨×§×˜×™"
    }
}


class ExpertAnalysisService:
    """
    Council of Experts Analysis System for meeting transcripts.
    Applies expert personas based on conversation context.
    Includes mandatory Kaizen feedback for personal growth.
    """
    
    def __init__(self):
        self.api_key = settings.google_api_key
        if self.api_key:
            genai.configure(api_key=self.api_key)
            try:
                self.model = genai.GenerativeModel('gemini-1.5-flash')
                logger.info("âœ… ×‘×©×™×¨×•×ª × ×™×ª×•×— ×”××•××—×™× ××•×ª×—×œ ×¢× Gemini 1.5 Flash")
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘××ª×—×•×œ ×”××•×“×œ: {e}")
                self.model = None
        else:
            self.model = None
            logger.warning("âš ï¸  ××¤×ª×— Google API ×œ× ××•×’×“×¨ - × ×™×ª×•×— ××•××—×™× ××•×©×‘×ª")
        
        self.is_configured = bool(self.api_key and self.model)
    
    def detect_persona(self, transcript_text: str, segments: List[Dict]) -> str:
        """
        Detect which expert persona to apply based on conversation content.
        Uses weighted keyword matching for accurate routing.
        """
        text_lower = transcript_text.lower()
        
        # Check each persona's trigger keywords with scoring
        scores = {}
        for persona_key, persona in EXPERT_PERSONAS.items():
            if persona_key == "general":
                continue
            score = sum(1 for kw in persona["trigger_keywords"] if kw in text_lower)
            scores[persona_key] = score
        
        # Return persona with highest score, or "general" if no matches
        if not scores or max(scores.values()) == 0:
            return "general"
        
        best_persona = max(scores, key=scores.get)
        print(f"   × ×™×ª×•×‘ ××•×˜×•××˜×™: {best_persona} (×¦×™×•×Ÿ: {scores[best_persona]})")
        return best_persona
    
    def build_expert_prompt(self, persona_key: str, segments: List[Dict], voice_map: Dict) -> str:
        """
        Build the analysis prompt for the selected expert persona.
        Includes mandatory Kaizen feedback section.
        """
        persona = EXPERT_PERSONAS.get(persona_key, EXPERT_PERSONAS["general"])
        israel_time = get_israel_time()
        
        # Build readable transcript with speaker names (RTL-friendly)
        transcript_lines = []
        for seg in segments:
            speaker_id = seg.get("speaker", "×“×•×‘×¨ ×œ× ××–×•×”×”")
            # Replace speaker ID with name if known
            speaker_name = voice_map.get(speaker_id.lower(), speaker_id)
            if speaker_name == speaker_id:
                # Try without case sensitivity
                for key, value in voice_map.items():
                    if key.lower() == speaker_id.lower():
                        speaker_name = value
                        break
            text = seg.get("text", "")
            transcript_lines.append(f"**{speaker_name}**: {text}")
        
        transcript_text = "\n".join(transcript_lines)
        
        prompt = f"""××ª×” ×—×‘×¨ ×‘××•×¢×¦×ª ×”××•××—×™× ×©×œ "×”××•×— ×”×©× ×™" (Second Brain).

**×”×¤×¨×¡×•× ×” ×©×œ×š:** {persona['name']}

**×”×’×™×©×” ×•×”××ª×•×“×•×œ×•×’×™×” ×©×œ×š:**
{persona['focus']}

**×”×˜×•×Ÿ ×©×œ×š:**
{persona['tone']}

**×–××Ÿ ×”× ×™×ª×•×—:** {israel_time.strftime('%d/%m/%Y %H:%M')} (×©×¢×•×Ÿ ×™×©×¨××œ)

---

**×ª××œ×™×œ ×”×©×™×—×”:**
{transcript_text}

---

**×”× ×—×™×•×ª ×—×©×•×‘×•×ª:**
1. ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“
2. ×”×©×ª××© ×‘×©××•×ª ×”×“×•×‘×¨×™× ×”×××™×ª×™×™× (×œ× "×“×•×‘×¨ 1" ××• "Speaker 2")
3. ×”×™×” ×¡×¤×¦×™×¤×™ ×•×¤×¨×§×˜×™ - ×ª×•×‘× ×•×ª ×©××¤×©×¨ ×œ×™×™×©×
4. ×›×©×™×© ××™×œ×™× ×‘×× ×’×œ×™×ª, ×”×ª×—×œ ××ª ×”××©×¤×˜ ×‘×¢×‘×¨×™×ª ×œ×ª××™×›×” ×‘-RTL
   (×œ××©×œ: "×‘×¨×’×¢×™× ××œ×” Cursor ×”×—×œ...")

---

**×‘×¦×¢ × ×™×ª×•×— ××§×™×£ ×‘×¤×•×¨××˜ ×”×‘×:**

ğŸ¯ **×¡× ×˜×™×× ×˜ ×›×œ×œ×™:**
[×—×™×•×‘×™/×©×œ×™×œ×™/××¢×•×¨×‘ - ×¢× ×”×¡×‘×¨ ×§×¦×¨ ×¢×œ ×”××•×•×™×¨×” ×”×›×œ×œ×™×ª]

ğŸ“‹ **×ª×§×¦×™×¨ ×× ×”×œ×™× (Executive Summary):**
[3-4 ××©×¤×˜×™× ×©××¡×›××™× ××ª ×¢×™×§×¨×™ ×”×©×™×—×” - ××” × ×“×•×Ÿ, ××” ×”×•×—×œ×˜, ××” × ×©××¨ ×¤×ª×•×—]

ğŸ” **×ª×•×‘× ×•×ª ×”××•××—×” ({persona['short_name']}):**
[2-3 ×ª×•×‘× ×•×ª ×¢××•×§×•×ª ×× ×§×•×“×ª ×”××‘×˜ ×©×œ ×”××•××—×™×•×ª ×©×œ×š. ××” ×§×•×¨×” ××ª×—×ª ×œ×¤× ×™ ×”×©×˜×—? ××” ×”×“×™× ××™×§×” ×”×××™×ª×™×ª?]

ğŸ‘¥ **××™ ×××¨ ××” (×¡×™×›×•× ×œ×¤×™ ×“×•×‘×¨×™×):**
[×œ×›×œ ×“×•×‘×¨:
- **[×©×]**: ×¢××“×”/×”×¦×¢×”/×”×—×œ×˜×” ×¢×™×§×¨×™×ª
]

âœ… **××§×©×Ÿ ××™×™×˜××¡ (××©×™××•×ª):**
[××©×™××•×ª ×¡×¤×¦×™×¤×™×•×ª ×¢× ××—×¨××™×:
- **[×©×]**: ××©×™××” ×§×•× ×§×¨×˜×™×ª
××•: "×œ× ×–×•×”×• ××©×™××•×ª ×¡×¤×¦×™×¤×™×•×ª"]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ˆ **×¤×™×“×‘×§ ×œ×¦××™×—×” (Kaizen)**
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… **×œ×©×™××•×¨ (××” ×”×™×” ×˜×•×‘):**
[1-2 ×”×ª× ×”×’×•×™×•×ª/×”×—×œ×˜×•×ª/×“×¤×•×¡×™ ×ª×§×©×•×¨×ª ×—×™×•×‘×™×™× ×©×¨××•×™ ×œ×©××¨. ×× ×œ× ×–×•×”×” ××©×”×• ×‘×•×œ×˜ - ××¤×©×¨ ×œ×“×œ×’]

ğŸ¯ **×œ×©×™×¤×•×¨ (×”×–×“×× ×•×ª ×œ×¦××™×—×”):**
[**×—×•×‘×”!** ×’× ×‘×©×™×—×” ×˜×•×‘×” ×™×© ×ª××™×“ ×”×–×“×× ×•×ª ×œ-Level Up.
×“×•×’×××•×ª:
- "×œ×©××•×œ ×™×•×ª×¨ ×©××œ×•×ª ×¤×ª×•×—×•×ª"
- "×œ×”×’×“×™×¨ KPI ×‘×¨×•×¨ ×™×•×ª×¨"
- "×œ×”×©×ª××© ×‘×©×¤×” ××¢×•×“×“×ª ×™×•×ª×¨"
- "×œ×ª×ª ×™×•×ª×¨ ××¨×—×‘ ×œ×¦×“ ×”×©× ×™ ×œ×“×‘×¨"
×¦×™×™×Ÿ ×“×•×’××” ×¡×¤×¦×™×¤×™×ª ××”×©×™×—×” ×× ××¤×©×¨]

â“ **×©××œ×” ×œ××—×©×‘×”:**
[×©××œ×” ×¤×¨×•×‘×•×§×˜×™×‘×™×ª ××—×ª ×©×ª×¢×–×•×¨ ×œ×¦××™×—×” ××™×©×™×ª]
"""
        return prompt
    
    async def analyze_transcript(
        self,
        segments: List[Dict],
        voice_map: Optional[Dict] = None,
        force_persona: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Perform expert analysis on a transcript with Kaizen feedback.
        
        Args:
            segments: List of transcript segments
            voice_map: Optional mapping of speaker IDs to names
            force_persona: Optional - force a specific persona
            
        Returns:
            Dict with analysis results including Kaizen feedback
        """
        if not self.is_configured:
            return {
                "success": False,
                "error": "×©×™×¨×•×ª × ×™×ª×•×— ×”××•××—×™× ×œ× ××•×’×“×¨"
            }
        
        voice_map = voice_map or {}
        
        # Build transcript text for persona detection
        transcript_text = " ".join(seg.get("text", "") for seg in segments)
        
        # Detect or use forced persona
        if force_persona and force_persona in EXPERT_PERSONAS:
            persona_key = force_persona
            print(f"ğŸ§  [× ×™×ª×•×— ××•××—×”] ×¤×¨×¡×•× ×” × ×›×¤×™×ª: {force_persona}")
        else:
            persona_key = self.detect_persona(transcript_text, segments)
        
        persona = EXPERT_PERSONAS[persona_key]
        print(f"ğŸ§  [× ×™×ª×•×— ××•××—×”] ×¤×¨×¡×•× ×” × ×‘×—×¨×”: {persona['name']}")
        
        # Build and send prompt
        prompt = self.build_expert_prompt(persona_key, segments, voice_map)
        
        try:
            response = self.model.generate_content(
                prompt,
                generation_config={
                    'temperature': 0.4,
                    'max_output_tokens': 2500
                }
            )
            
            analysis_text = response.text if response.text else ""
            israel_time = get_israel_time()
            
            return {
                "success": True,
                "persona": persona["name"],
                "persona_key": persona_key,
                "raw_analysis": analysis_text,
                "timestamp": israel_time.isoformat(),
                "timestamp_display": israel_time.strftime('%d/%m/%Y %H:%M')
            }
            
        except Exception as e:
            logger.error(f"âŒ × ×™×ª×•×— ××•××—×” × ×›×©×œ: {e}")
            return {
                "success": False,
                "error": str(e),
                "persona": persona["name"]
            }
    
    def format_for_whatsapp(self, analysis_result: Dict, include_header: bool = True) -> str:
        """
        Format the expert analysis for WhatsApp message.
        RTL-friendly formatting with clear sections.
        
        Args:
            analysis_result: Result from analyze_transcript
            include_header: Whether to include the decorative header
            
        Returns:
            Formatted WhatsApp message string
        """
        if not analysis_result.get("success"):
            error = analysis_result.get('error', '×©×’×™××” ×œ× ×™×“×•×¢×”')
            return f"âš ï¸ ×œ× ×”×¦×œ×—×ª×™ ×œ×‘×¦×¢ × ×™×ª×•×— ××•××—×”: {error}"
        
        persona = analysis_result.get("persona", "×¢×•×–×¨ ××™×©×™")
        raw = analysis_result.get("raw_analysis", "")
        timestamp = analysis_result.get("timestamp_display", "")
        
        # Build message with RTL-friendly header
        message = ""
        
        if include_header:
            message += f"ğŸ§  *× ×™×ª×•×— ××•×¢×¦×ª ×”××•××—×™×*\n"
            message += f"ğŸ“Š ×¤×¨×¡×•× ×”: *{persona}*\n"
            if timestamp:
                message += f"â° ×–××Ÿ: {timestamp} (×©×¢×•×Ÿ ×™×©×¨××œ)\n"
            message += "â•" * 25 + "\n\n"
        
        # Add the raw analysis (already formatted by Gemini)
        message += raw
        
        # Trim if too long for WhatsApp (4096 char limit, leave buffer)
        if len(message) > 3800:
            message = message[:3700] + "\n\n... (×”× ×™×ª×•×— ×”××œ× × ×©××¨ ×‘×“×¨×™×™×‘)"
        
        return message
    
    def save_analysis_to_drive(
        self,
        analysis_result: Dict,
        transcript_file_id: str,
        drive_service
    ) -> Optional[str]:
        """
        Save the expert analysis as a companion file to the transcript.
        This enables retroactive updates when speakers are identified.
        
        Returns:
            File ID of saved analysis, or None if failed
        """
        if not analysis_result.get("success"):
            return None
        
        try:
            # Build analysis document
            analysis_doc = {
                "persona": analysis_result.get("persona"),
                "persona_key": analysis_result.get("persona_key"),
                "analysis": analysis_result.get("raw_analysis"),
                "timestamp": analysis_result.get("timestamp"),
                "transcript_file_id": transcript_file_id
            }
            
            # Save via drive service if available
            # This would be implemented in drive_memory_service
            # For now, the analysis is included in the main transcript save
            return None
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×©××™×¨×ª × ×™×ª×•×—: {e}")
            return None


# Singleton instance
expert_analysis_service = ExpertAnalysisService()
